{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                  \tstd                \tmin              \tmax              \n",
      "0  \t50    \t[-10000.       11.86]\t[0.       2.638257]\t[-1.e+04  6.e+00]\t[-10000.     18.]\n",
      "1  \t26    \t[-1.00e+04  9.76e+00]\t[0.         1.83913023]\t[-1.e+04  6.e+00]\t[-10000.     16.]\n",
      "2  \t37    \t[-8.99993053e+03  8.06000000e+00]\t[3.00020840e+03 1.84835062e+00]\t[-1.e+04  3.e+00]\t[ 0.85333333 12.        ]\n",
      "3  \t34    \t[-7.79986733e+03  6.78000000e+00]\t[4.14271284e+03 1.78089865e+00]\t[-1.e+04  3.e+00]\t[ 0.85333333 12.        ]\n",
      "4  \t23    \t[-5599.79253333     5.78      ]  \t[4.96410351e+03 1.30061524e+00]\t[-1.e+04  3.e+00]\t[ 0.85333333 10.        ]\n",
      "5  \t26    \t[-4399.69693333     5.42      ]  \t[4.96413810e+03 1.18473626e+00]\t[-1.e+04  3.e+00]\t[ 0.85333333 10.        ]\n",
      "6  \t28    \t[-2999.59493333     5.1       ]  \t[4.58284088e+03 1.04403065e+00]\t[-1.e+04  2.e+00]\t[0.85333333 8.        ]  \n",
      "7  \t24    \t[-1599.4052     4.64  ]          \t[3.66632015e+03 1.01508620e+00]\t[-1.e+04  2.e+00]\t[0.85333333 7.        ]  \n",
      "8  \t31    \t[-1399.29933333     4.42      ]  \t[3.47015302e+03 1.02156742e+00]\t[-1.e+04  2.e+00]\t[0.85333333 7.        ]  \n",
      "9  \t29    \t[-799.2184    4.02  ]            \t[2.71316247e+03 9.48472456e-01]\t[-1.e+04  2.e+00]\t[0.85333333 6.        ]  \n",
      "10 \t30    \t[0.84333333 3.28      ]          \t[0.07      0.7222188]          \t[0.35333333 2.        ]\t[0.85333333 5.        ]  \n",
      "11 \t25    \t[0.85493333 2.86      ]          \t[0.0112     0.72138755]        \t[0.85333333 1.        ]\t[0.93333333 5.        ]  \n",
      "12 \t30    \t[0.85053333 2.76      ]          \t[0.07167941 1.14122741]        \t[0.37333333 1.        ]\t[0.94 5.  ]              \n",
      "13 \t31    \t[0.87533333 2.76      ]          \t[0.03603085 1.36469777]        \t[0.85333333 1.        ]\t[0.94 5.  ]              \n",
      "14 \t29    \t[-1399.21906667     4.08      ]  \t[3.47018540e+03 1.79822134e+00]\t[-1.e+04  1.e+00]      \t[0.94 8.  ]              \n",
      "15 \t31    \t[-599.11986667    4.22      ]    \t[2.37509078e+03 9.44245731e-01]\t[-1.e+04  2.e+00]      \t[0.95333333 6.        ]  \n",
      "16 \t31    \t[-199.07893333    3.54      ]    \t[1.40013158e+03 8.53463532e-01]\t[-1.e+04  2.e+00]      \t[0.94 6.  ]              \n",
      "17 \t34    \t[0.93666667 3.16      ]          \t[0.01361372 0.83330667]        \t[0.85333333 1.        ]\t[0.94 5.  ]              \n",
      "18 \t33    \t[0.94053333 2.9       ]          \t[0.00261279 0.85440037]        \t[0.94 2.  ]            \t[0.95333333 5.        ]  \n",
      "19 \t31    \t[0.9424 2.8   ]                  \t[0.0051225  0.91651514]        \t[0.94 2.  ]            \t[0.95333333 5.        ]  \n",
      "20 \t24    \t[-399.092    3.24 ]              \t[1.95977714e+03 1.22572428e+00]\t[-1.e+04  2.e+00]      \t[0.95333333 6.        ]  \n",
      "21 \t35    \t[-599.10933333    3.92      ]    \t[2.37509344e+03 9.96794864e-01]\t[-1.e+04  2.e+00]      \t[0.95333333 7.        ]  \n",
      "22 \t35    \t[-199.06586667    3.92      ]    \t[1.40013345e+03 9.13016977e-01]\t[-1.e+04  3.e+00]      \t[0.96 8.  ]              \n",
      "23 \t26    \t[0.9516 3.46  ]                  \t[0.01311894 0.66962676]        \t[0.86 3.  ]            \t[0.96 5.  ]              \n",
      "24 \t39    \t[-199.06613333    3.52      ]    \t[1.40013341e+03 8.30421580e-01]\t[-1.e+04  3.e+00]      \t[0.96 6.  ]              \n",
      "25 \t31    \t[-399.0852    3.52  ]            \t[1.95977853e+03 9.43186090e-01]\t[-1.e+04  2.e+00]      \t[0.96 7.  ]              \n",
      "26 \t31    \t[-999.1396    4.14  ]            \t[3.00028680e+03 1.03942292e+00]\t[-1.e+04  3.e+00]      \t[0.96 7.  ]              \n",
      "27 \t33    \t[-599.10386667    4.24      ]    \t[2.37509482e+03 7.88923317e-01]\t[-1.e+04  2.e+00]      \t[0.96 6.  ]              \n",
      "28 \t21    \t[-599.09906667    4.18      ]    \t[2.37509603e+03 7.12460525e-01]\t[-1.e+04  2.e+00]      \t[0.96 7.  ]              \n",
      "29 \t28    \t[-399.0796    4.14  ]            \t[1.95977967e+03 5.66038868e-01]\t[-1.e+04  3.e+00]      \t[0.96 7.  ]              \n",
      "30 \t25    \t[-199.0616    4.14  ]            \t[1.40013406e+03 4.47660586e-01]\t[-1.e+04  3.e+00]      \t[0.96 6.  ]              \n",
      "31 \t29    \t[-599.09773333    4.2       ]    \t[2.37509637e+03 5.29150262e-01]\t[-1.e+04  4.e+00]      \t[0.96 6.  ]              \n",
      "32 \t33    \t[-399.07853333    4.14      ]    \t[1.95977989e+03 5.66038868e-01]\t[-1.e+04  3.e+00]      \t[0.96 7.  ]              \n",
      "33 \t30    \t[-399.0784    4.1   ]            \t[1.95977992e+03 5.00000000e-01]\t[-1.e+04  4.e+00]      \t[0.96 7.  ]              \n",
      "34 \t31    \t[0.95826667 4.06      ]          \t[0.00830636 0.23748684]        \t[0.90666667 4.        ]\t[0.96 5.  ]              \n",
      "[ True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "\n",
    "\n",
    "def main():\n",
    "    iris = datasets.load_iris()\n",
    "\n",
    "    # Some noisy data not correlated\n",
    "    E = np.random.uniform(0, 0.1, size=(len(iris.data), 20))\n",
    "\n",
    "    X = np.hstack((iris.data, E))\n",
    "    y = iris.target\n",
    "\n",
    "    estimator = linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "\n",
    "    selector = GeneticSelectionCV(estimator,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=5,\n",
    "                                  n_population=50,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=40,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    print(selector.support_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
      "        9.1400e+00],\n",
      "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00],\n",
      "       ...,\n",
      "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        5.6400e+00],\n",
      "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
      "        6.4800e+00],\n",
      "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
      "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
      "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
      "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
      "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
      "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
      "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
      "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
      "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
      "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
      "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
      "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
      "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
      "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
      "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
      "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
      "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
      "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
      "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
      "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
      "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
      "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
      "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
      "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
      "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
      "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
      "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
      "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
      "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
      "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
      "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
      "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
      "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
      "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
      "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
      "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
      "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
      "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
      "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
      "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
      "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
      "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
      "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \"Boston House Prices dataset\\n===========================\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\"}\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "SEED = 2018\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#==============================================================================\n",
    "# Data \n",
    "#==============================================================================\n",
    "dataset = load_boston()\n",
    "print(dataset)\n",
    "X, y = dataset.data, dataset.target\n",
    "features = dataset.feature_names\n",
    "print(features)\n",
    "X, y = dataset.data, dataset.target\n",
    "features = dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE before feature selection: 37.22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE after feature selection: 28.92\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "SEED = 2018\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#==============================================================================\n",
    "# Data \n",
    "#==============================================================================\n",
    "dataset = load_boston()\n",
    "X, y = dataset.data, dataset.target\n",
    "features = dataset.feature_names\n",
    "\n",
    "#==============================================================================\n",
    "# CV MSE before feature selection\n",
    "#==============================================================================\n",
    "est = LinearRegression()\n",
    "score = -1.0 * cross_val_score(est, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))\n",
    "\n",
    "#==============================================================================\n",
    "# Class performing feature selection with genetic algorithm\n",
    "#==============================================================================\n",
    "class GeneticSelector():\n",
    "    def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
    "                 n_children, mutation_rate):\n",
    "        # Estimator \n",
    "        self.estimator = estimator\n",
    "        # Number of generations\n",
    "        self.n_gen = n_gen\n",
    "        # Number of chromosomes in population\n",
    "        self.size = size\n",
    "        # Number of best chromosomes to select\n",
    "        self.n_best = n_best\n",
    "        # Number of random chromosomes to select\n",
    "        self.n_rand = n_rand\n",
    "        # Number of children created during crossover\n",
    "        self.n_children = n_children\n",
    "        # Probablity of chromosome mutation\n",
    "        self.mutation_rate = mutation_rate\n",
    "        \n",
    "        if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
    "            raise ValueError(\"The population size is not stable.\")  \n",
    "            \n",
    "    def initilize(self):\n",
    "        population = []\n",
    "        for i in range(self.size):\n",
    "            chromosome = np.ones(self.n_features, dtype=np.bool)\n",
    "            mask = np.random.rand(len(chromosome)) < 0.3\n",
    "            chromosome[mask] = False\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "\n",
    "    def fitness(self, population):\n",
    "        X, y = self.dataset\n",
    "        scores = []\n",
    "        for chromosome in population:\n",
    "            score = -1.0 * np.mean(cross_val_score(self.estimator, X[:,chromosome], y, \n",
    "                                                       cv=5, \n",
    "                                                       scoring=\"neg_mean_squared_error\"))\n",
    "            scores.append(score)\n",
    "        scores, population = np.array(scores), np.array(population) \n",
    "        inds = np.argsort(scores)\n",
    "        return list(scores[inds]), list(population[inds,:])\n",
    "\n",
    "    def select(self, population_sorted):\n",
    "        population_next = []\n",
    "        for i in range(self.n_best):\n",
    "            population_next.append(population_sorted[i])\n",
    "        for i in range(self.n_rand):\n",
    "            population_next.append(random.choice(population_sorted))\n",
    "        random.shuffle(population_next)\n",
    "        return population_next\n",
    "\n",
    "    def crossover(self, population):\n",
    "        population_next = []\n",
    "        for i in range(int(len(population)/2)):\n",
    "            for j in range(self.n_children):\n",
    "                chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
    "                child = chromosome1\n",
    "                mask = np.random.rand(len(child)) > 0.5\n",
    "                child[mask] = chromosome2[mask]\n",
    "                population_next.append(child)\n",
    "        return population_next\n",
    "\t\n",
    "    def mutate(self, population):\n",
    "        population_next = []\n",
    "        for i in range(len(population)):\n",
    "            chromosome = population[i]\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mask = np.random.rand(len(chromosome)) < 0.05\n",
    "                chromosome[mask] = False\n",
    "            population_next.append(chromosome)\n",
    "        return population_next\n",
    "\n",
    "    def generate(self, population):\n",
    "        # Selection, crossover and mutation\n",
    "        scores_sorted, population_sorted = self.fitness(population)\n",
    "        population = self.select(population_sorted)\n",
    "        population = self.crossover(population)\n",
    "        population = self.mutate(population)\n",
    "        # History\n",
    "        self.chromosomes_best.append(population_sorted[0])\n",
    "        self.scores_best.append(scores_sorted[0])\n",
    "        self.scores_avg.append(np.mean(scores_sorted))\n",
    "        \n",
    "        return population\n",
    "\n",
    "    def fit(self, X, y):\n",
    " \n",
    "        self.chromosomes_best = []\n",
    "        self.scores_best, self.scores_avg  = [], []\n",
    "        \n",
    "        self.dataset = X, y\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        population = self.initilize()\n",
    "        for i in range(self.n_gen):\n",
    "            population = self.generate(population)\n",
    "            \n",
    "        return self \n",
    "    \n",
    "    @property\n",
    "    def support_(self):\n",
    "        return self.chromosomes_best[-1]\n",
    "\n",
    "    def plot_scores(self):\n",
    "        plt.plot(self.scores_best, label='Best')\n",
    "        plt.plot(self.scores_avg, label='Average')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Scores')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()\n",
    "\n",
    "sel = GeneticSelector(estimator=LinearRegression(), \n",
    "                      n_gen=7, size=200, n_best=40, n_rand=40, \n",
    "                      n_children=5, mutation_rate=0.05)\n",
    "sel.fit(X, y)\n",
    "sel.plot_scores()\n",
    "score = -1.0 * cross_val_score(est, X[:,sel.support_], y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
